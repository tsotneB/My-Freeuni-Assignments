{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0ee6ec-d8c7-4110-be08-e892f06571b2",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7191d4db-544f-4c4e-82bf-d1bc9fd048f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objs as go\n",
    "from plotly import subplots\n",
    "import plotly.offline as py\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16252c16-1834-4115-99c5-38f7216efb6c",
   "metadata": {},
   "source": [
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2daf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "data_df = pd.DataFrame(data, columns =['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dddc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ძეგლთა დაცვის ეროვნულ სააგენტოში აცხადებენ  რო...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>საქართველოს კულტურული მემკვიდრეობისა და ძეგლთა...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>გაირკვა  რომ აქ არც მეჩეთი და არც ეკლესია არ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>კვლევის ავტორი არ გამორიცხავს  რომ აქ სამხედრო...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>შეკითხვაზე  რამდენად შესაძლებელია რომ ეს რელიგ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  ძეგლთა დაცვის ეროვნულ სააგენტოში აცხადებენ  რო...\n",
       "1  საქართველოს კულტურული მემკვიდრეობისა და ძეგლთა...\n",
       "2   გაირკვა  რომ აქ არც მეჩეთი და არც ეკლესია არ ...\n",
       "3  კვლევის ავტორი არ გამორიცხავს  რომ აქ სამხედრო...\n",
       "4  შეკითხვაზე  რამდენად შესაძლებელია რომ ეს რელიგ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afd604",
   "metadata": {},
   "source": [
    "# Baseline Model (N-gram Language Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a601839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mosestokenizer in c:\\users\\tsotn\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: uctools in c:\\users\\tsotn\\anaconda3\\lib\\site-packages (from mosestokenizer) (1.3.0)\n",
      "Requirement already satisfied: docopt in c:\\users\\tsotn\\anaconda3\\lib\\site-packages (from mosestokenizer) (0.6.2)\n",
      "Requirement already satisfied: toolwrapper in c:\\users\\tsotn\\anaconda3\\lib\\site-packages (from mosestokenizer) (2.1.0)\n",
      "Requirement already satisfied: openfile in c:\\users\\tsotn\\anaconda3\\lib\\site-packages (from mosestokenizer) (0.0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install mosestokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c90adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from mosestokenizer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce5114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sentences into list of words\n",
    "corpus = list(sentence.split() for sentence in data_df[\"sentence\"])\n",
    "corpus = corpus[:int(len(corpus)*0.8)]    # part of corpus used lately for training\n",
    "testcorpus = corpus[int(len(corpus)*0.8) + 1:]   # part of corpus used lately as test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9acfe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687299"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de44a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8bc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace\n",
    "model = Laplace(n) # Lets train a 3-grams model, previously we set n=3 \n",
    "                   # use laplace model to avoid problems related to unrecognized words during perplexity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a33fb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)    # it should be 0, because both train and vocab are lazy iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "134887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409b6809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483820\n"
     ]
    }
   ],
   "source": [
    "print(len(model.vocab))    # now that we have fit our model, vocab should be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b91720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 28651872 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26ef302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028648612660669287"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"აქვს\", [\"მას\"])   # chance that \"აქვს\" is preceded by \"მას\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0688d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b23272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert generated sequence of words into actual sentence\n",
    "def generate_sentence(model, num_words, random_seed=42):\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e50e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'თვისებით დიდი სათამაშო ვარიანტი ამ სიაში მაგრამ ჯერ ჯერობით თარგმნილი არ არის ბარათელი ის ალაპარაკდება'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, num_words=20, random_seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e6f77b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'სფეროში სადაც ეს კომენტარია გაკეთებული'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, num_words=20, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55fee88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'იბერ იბერია ტერმინთა წარმომავლობისათვის'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, num_words=20, random_seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e677436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'მალკოლმ ლიტლი შეიცვალა და საქართველოს შორის'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, num_words=20, random_seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa81cf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'წულუკიანის ახლობელია'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, num_words=20, random_seed=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bf1accc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'იწონება არაფერია ჩვეულებრივი და ბანალური ვერ გახდებოდა ბაზრის სენსაცია მომხმარებლებმა უბრალოდ შეიძულეს ეს მოწყობილობა კითხულობს ადამიანის ტვინის სიმძლავრის ტოლი გახდება'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(model, num_words=20, random_seed=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d5314",
   "metadata": {},
   "source": [
    "# Perplexity on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604e0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = flatten(list(ngrams(sent,n=3) for sent in testcorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1c76d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170344.31387370508"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.perplexity(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
