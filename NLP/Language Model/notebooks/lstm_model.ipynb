{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:00:53.993671Z",
     "iopub.status.busy": "2022-07-27T13:00:53.992988Z",
     "iopub.status.idle": "2022-07-27T13:01:17.424241Z",
     "shell.execute_reply": "2022-07-27T13:01:17.422660Z",
     "shell.execute_reply.started": "2022-07-27T13:00:53.993610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: torchtext in c:\\programdata\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: torch==1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (1.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (1.20.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.12.0->torchtext) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (4.0.0)\n",
      "Requirement already satisfied: mosestokenizer in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: toolwrapper in c:\\programdata\\anaconda3\\lib\\site-packages (from mosestokenizer) (2.1.0)\n",
      "Requirement already satisfied: openfile in c:\\programdata\\anaconda3\\lib\\site-packages (from mosestokenizer) (0.0.7)\n",
      "Requirement already satisfied: docopt in c:\\programdata\\anaconda3\\lib\\site-packages (from mosestokenizer) (0.6.2)\n",
      "Requirement already satisfied: uctools in c:\\programdata\\anaconda3\\lib\\site-packages (from mosestokenizer) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install torch\n",
    "!pip install torchtext\n",
    "!pip install mosestokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:17.428819Z",
     "iopub.status.busy": "2022-07-27T13:01:17.428308Z",
     "iopub.status.idle": "2022-07-27T13:01:17.440896Z",
     "shell.execute_reply": "2022-07-27T13:01:17.439259Z",
     "shell.execute_reply.started": "2022-07-27T13:01:17.428773Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from mosestokenizer import *\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:17.443359Z",
     "iopub.status.busy": "2022-07-27T13:01:17.442957Z",
     "iopub.status.idle": "2022-07-27T13:01:21.623292Z",
     "shell.execute_reply": "2022-07-27T13:01:21.622257Z",
     "shell.execute_reply.started": "2022-07-27T13:01:17.443315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ძეგლთა დაცვის ეროვნულ სააგენტოში აცხადებენ  რომ მათ მიერ  სამხრეთის კარიბჭესთვის  მოწოდებული ინფორმაცია  იმის შესახებ რომ ახალციხის არქივის ეზოში აღმოჩენილი შენობა საკულტო ნაგებობა იყო არასწორია და საბოლოოდ დადგინდა  რომ აქ ტრადიციული მესხური საცხოვრებელი იყო',\n",
       "       'საქართველოს კულტურული მემკვიდრეობისა და ძეგლთა დაცვის ეროვნულ სააგენტოში აცხადებენ რომ მათ მიერ მოწოდებული პირველადი ინფორმაცია ახალციხის არქივის ეზოში აღმოჩენის შესახებ ნაჩქარევი იყო',\n",
       "       ' გაირკვა  რომ აქ არც მეჩეთი და არც ეკლესია არ ყოფილა  ჩვეულებრივი საყოფაცხოვრებო დანიშნულების შენობა  ტრადიციული მესხური საცხოვრისი იყო     გვითხრეს კულტურული მემკვიდრეობისა და ძეგლთა დაცვის ეროვნული სააგენტოს საზოგადოებასთან ურთიერთობის სამსახურში',\n",
       "       'კვლევის ავტორი არ გამორიცხავს  რომ აქ სამხედრო  ან თუნდაც რელიგიური დანიშნულების ობიექტიც ყოფილიყო',\n",
       "       'შეკითხვაზე  რამდენად შესაძლებელია რომ ეს რელიგიური დანიშნულების ობიექტი მეჩეთი ყოფილიყო  რომლის ნანგრევებზეც ტაძარი აშენდა  ჩოხელი გვპასუხობს '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pd.read_csv('../data/data.csv',nrows=100000).values.flatten()\n",
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:21.628046Z",
     "iopub.status.busy": "2022-07-27T13:01:21.626756Z",
     "iopub.status.idle": "2022-07-27T13:01:25.780299Z",
     "shell.execute_reply": "2022-07-27T13:01:25.778734Z",
     "shell.execute_reply.started": "2022-07-27T13:01:21.627986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = len(sequences)\n",
    "nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sequences[:int(nrows*0.9)]\n",
    "test = sequences[int(nrows*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:25.782509Z",
     "iopub.status.busy": "2022-07-27T13:01:25.782128Z",
     "iopub.status.idle": "2022-07-27T13:01:25.943261Z",
     "shell.execute_reply": "2022-07-27T13:01:25.941785Z",
     "shell.execute_reply.started": "2022-07-27T13:01:25.782475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sequence_len = (sum([len(x.split()) for x in sequences]) // len(sequences))\n",
    "avg_sequence_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words To Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139769"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# end of sentence <eos>\n",
    "word_counts = collections.Counter()\n",
    "word_counts['<pad>'] = 1\n",
    "\n",
    "for sentence in train:\n",
    "    for word in sentence.split():\n",
    "        word_counts[word] += 1\n",
    "        \n",
    "unique_words = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "vocab_size = len(unique_words) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index: word for index, word in enumerate(unique_words)}\n",
    "word_to_index = {word: index for index, word in enumerate(unique_words)}\n",
    "\n",
    "for i in range(len(train)):\n",
    "    train[i] = [word_to_index[w] for w in train[i].split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train დატა ინდექსებზეა გადაყვანილი, ახლა შევქმნათ n-gram-ები"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:25.945310Z",
     "iopub.status.busy": "2022-07-27T13:01:25.944911Z",
     "iopub.status.idle": "2022-07-27T13:01:32.964678Z",
     "shell.execute_reply": "2022-07-27T13:01:32.963386Z",
     "shell.execute_reply.started": "2022-07-27T13:01:25.945271Z"
    }
   },
   "outputs": [],
   "source": [
    "# make n-grams\n",
    "input_train = []\n",
    "pad_index = word_to_index['<pad>']\n",
    "n_gram_size = avg_sequence_len // 2\n",
    "\n",
    "def pad(x):\n",
    "    if len(x) < avg_sequence_len:\n",
    "            x += [pad_index] * (avg_sequence_len - len(x))\n",
    "    return x\n",
    "\n",
    "for line in train:\n",
    "    pad(line)\n",
    "    for i in range(len(line) - n_gram_size):\n",
    "        n_gram_sequence = line[i:i+n_gram_size]\n",
    "        input_train.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec.load('../resources/georgian_word2vec.model')\n",
    "w2v = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.08971679e-01 -1.51449752e+00 -8.97826731e-01 -9.29931104e-02\n",
      " -3.34778619e+00 -8.85849833e-01 -6.82361305e-01  1.93264365e-01\n",
      "  1.97973764e+00 -1.07326366e-01  3.75844568e-01 -6.44773543e-01\n",
      "  1.80105960e+00  2.66361976e+00 -1.42565429e-01 -8.48135114e-01\n",
      " -4.20123070e-01 -6.38693333e-01 -8.47258493e-02 -4.58429670e+00\n",
      "  2.47888422e+00 -4.70472813e-01 -1.83740878e+00 -1.54331994e+00\n",
      "  2.82247686e+00  6.75757647e-01  5.92679381e-01 -5.76169007e-02\n",
      " -4.95996892e-01  1.02046371e+00  3.27344686e-02  2.66266316e-01\n",
      "  1.92116630e+00  2.80386899e-02 -8.97139549e-01 -4.46181923e-01\n",
      " -2.34353319e-01  1.40998244e+00  2.35253856e-01 -1.94278586e+00\n",
      "  3.92591208e-01  2.01633668e+00  3.61283004e-01  2.23645076e-01\n",
      "  1.81451428e+00  6.71006590e-02 -4.94771689e-01  1.72819376e-01\n",
      "  7.52462447e-01  1.20438778e+00 -1.84228584e-01  1.71239960e+00\n",
      "  5.51109135e-01 -1.54601228e+00  5.62165737e-01  1.66284513e+00\n",
      " -4.30989981e-01  1.80961800e+00  1.11002803e+00  3.20753306e-01\n",
      " -6.98449314e-01 -7.56222084e-02  1.80984497e-01  1.22867785e-01\n",
      " -7.65457094e-01 -1.10852063e+00  6.49195537e-02 -3.37102622e-01\n",
      "  8.19184235e-04  1.37557864e+00 -1.34025753e-01  7.77557731e-01\n",
      "  6.62464738e-01  9.60875228e-02  1.53547788e+00 -3.01986724e-01\n",
      "  1.22751880e+00 -7.37072006e-02 -3.23093265e-01  8.73106658e-01\n",
      "  3.86586159e-01 -7.00675309e-01 -6.89664602e-01 -8.09681475e-01\n",
      " -5.95967948e-01  1.35200107e+00 -1.03340900e+00 -3.58229131e-01\n",
      " -1.32539296e+00 -3.19724321e-01  1.87410057e+00  1.91652250e+00\n",
      " -1.19271731e+00  1.19578397e+00  8.18934083e-01 -1.10047913e+00\n",
      "  6.20073259e-01  5.35979152e-01 -1.73674718e-01  2.30504081e-01]\n"
     ]
    }
   ],
   "source": [
    "print(w2v['კაცი'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_embedings = {}\n",
    "\n",
    "for idx, token in index_to_word.items():\n",
    "    try:\n",
    "        index_to_embedings[idx] = w2v[token]\n",
    "    except:\n",
    "        index_to_embedings[idx] = torch.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.08971679e-01 -1.51449752e+00 -8.97826731e-01 -9.29931104e-02\n",
      " -3.34778619e+00 -8.85849833e-01 -6.82361305e-01  1.93264365e-01\n",
      "  1.97973764e+00 -1.07326366e-01  3.75844568e-01 -6.44773543e-01\n",
      "  1.80105960e+00  2.66361976e+00 -1.42565429e-01 -8.48135114e-01\n",
      " -4.20123070e-01 -6.38693333e-01 -8.47258493e-02 -4.58429670e+00\n",
      "  2.47888422e+00 -4.70472813e-01 -1.83740878e+00 -1.54331994e+00\n",
      "  2.82247686e+00  6.75757647e-01  5.92679381e-01 -5.76169007e-02\n",
      " -4.95996892e-01  1.02046371e+00  3.27344686e-02  2.66266316e-01\n",
      "  1.92116630e+00  2.80386899e-02 -8.97139549e-01 -4.46181923e-01\n",
      " -2.34353319e-01  1.40998244e+00  2.35253856e-01 -1.94278586e+00\n",
      "  3.92591208e-01  2.01633668e+00  3.61283004e-01  2.23645076e-01\n",
      "  1.81451428e+00  6.71006590e-02 -4.94771689e-01  1.72819376e-01\n",
      "  7.52462447e-01  1.20438778e+00 -1.84228584e-01  1.71239960e+00\n",
      "  5.51109135e-01 -1.54601228e+00  5.62165737e-01  1.66284513e+00\n",
      " -4.30989981e-01  1.80961800e+00  1.11002803e+00  3.20753306e-01\n",
      " -6.98449314e-01 -7.56222084e-02  1.80984497e-01  1.22867785e-01\n",
      " -7.65457094e-01 -1.10852063e+00  6.49195537e-02 -3.37102622e-01\n",
      "  8.19184235e-04  1.37557864e+00 -1.34025753e-01  7.77557731e-01\n",
      "  6.62464738e-01  9.60875228e-02  1.53547788e+00 -3.01986724e-01\n",
      "  1.22751880e+00 -7.37072006e-02 -3.23093265e-01  8.73106658e-01\n",
      "  3.86586159e-01 -7.00675309e-01 -6.89664602e-01 -8.09681475e-01\n",
      " -5.95967948e-01  1.35200107e+00 -1.03340900e+00 -3.58229131e-01\n",
      " -1.32539296e+00 -3.19724321e-01  1.87410057e+00  1.91652250e+00\n",
      " -1.19271731e+00  1.19578397e+00  8.18934083e-01 -1.10047913e+00\n",
      "  6.20073259e-01  5.35979152e-01 -1.73674718e-01  2.30504081e-01]\n"
     ]
    }
   ],
   "source": [
    "print(index_to_embedings[word_to_index['კაცი']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = [x for _, x in index_to_embedings.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4189, 342, 651, 5760, 1955],\n",
       " [342, 651, 5760, 1955, 2],\n",
       " [651, 5760, 1955, 2, 37],\n",
       " [5760, 1955, 2, 37, 46],\n",
       " [1955, 2, 37, 46, 2463]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:32.974317Z",
     "iopub.status.busy": "2022-07-27T13:01:32.974002Z",
     "iopub.status.idle": "2022-07-27T13:01:32.985750Z",
     "shell.execute_reply": "2022-07-27T13:01:32.984260Z",
     "shell.execute_reply.started": "2022-07-27T13:01:32.974288Z"
    }
   },
   "outputs": [],
   "source": [
    "def index_to_vec(index):\n",
    "    word = index_to_word[index]\n",
    "    try:\n",
    "        return torch.tensor(w2v[word])\n",
    "    except:\n",
    "        return torch.zeros(100)\n",
    "    \n",
    "# pad or strip data, also add <eos>\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for x in batch:\n",
    "        label_list.append(x[1:])\n",
    "        x = x[:-1]\n",
    "        text_list.append(torch.Tensor(x).long())\n",
    "    text_list = torch.stack(text_list, dim=0)\n",
    "    label_list = torch.Tensor(label_list).long()\n",
    "    \n",
    "    return text_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T13:01:32.988247Z",
     "iopub.status.busy": "2022-07-27T13:01:32.987092Z",
     "iopub.status.idle": "2022-07-27T13:01:34.312360Z",
     "shell.execute_reply": "2022-07-27T13:01:34.310855Z",
     "shell.execute_reply.started": "2022-07-27T13:01:32.988207Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "train_dl = DataLoader(input_train[:int(len(input_train)*0.7)], \n",
    "                      batch_size=batch_size, \n",
    "                      shuffle=True, \n",
    "                      collate_fn=collate_batch)\n",
    "\n",
    "valid_dl = DataLoader(input_train[int(len(input_train)*0.7):], \n",
    "                      batch_size=batch_size, \n",
    "                      shuffle=False, \n",
    "                      collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,*, n_vocab, num_layers, embedding_dim, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_vocab = n_vocab\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.emb = nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(embedding_vectors), \n",
    "            freeze=False\n",
    "        ) \n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        x = self.emb(x)\n",
    "        output, state = self.lstm(x, (h0, c0))\n",
    "        logits = self.fc(output)\n",
    "        return logits, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=2\n",
    "embedding_dim=100\n",
    "hidden_size=128\n",
    "seq_len = n_gram_size-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 11.860724449157715, 'perplexity': 141594.7593274818}\n",
      "{'epoch': 0, 'batch': 10, 'loss': 11.800698280334473, 'perplexity': 133345.43293729678}\n",
      "{'epoch': 0, 'batch': 20, 'loss': 11.485949516296387, 'perplexity': 97338.4652434557}\n",
      "{'epoch': 0, 'batch': 30, 'loss': 10.450186729431152, 'perplexity': 34550.8257629988}\n",
      "{'epoch': 0, 'batch': 40, 'loss': 9.45033073425293, 'perplexity': 12712.368984329485}\n",
      "{'epoch': 0, 'batch': 50, 'loss': 9.441768646240234, 'perplexity': 12603.989202952747}\n",
      "{'epoch': 0, 'batch': 60, 'loss': 9.130753517150879, 'perplexity': 9234.978062445525}\n",
      "{'epoch': 0, 'batch': 70, 'loss': 9.256898880004883, 'perplexity': 10476.593737601084}\n",
      "{'epoch': 0, 'batch': 80, 'loss': 9.193681716918945, 'perplexity': 9834.793330423528}\n",
      "{'epoch': 0, 'batch': 90, 'loss': 9.114057540893555, 'perplexity': 9082.071105396599}\n",
      "{'epoch': 0, 'batch': 100, 'loss': 9.513969421386719, 'perplexity': 13547.664114683561}\n",
      "{'epoch': 0, 'batch': 110, 'loss': 9.10488224029541, 'perplexity': 8999.121498672084}\n",
      "{'epoch': 0, 'batch': 120, 'loss': 9.267465591430664, 'perplexity': 10587.883829987226}\n",
      "{'epoch': 0, 'batch': 130, 'loss': 9.336797714233398, 'perplexity': 11348.010420926026}\n",
      "{'epoch': 0, 'batch': 140, 'loss': 9.217866897583008, 'perplexity': 10075.54921095767}\n",
      "{'epoch': 0, 'batch': 150, 'loss': 9.031084060668945, 'perplexity': 8358.916234628176}\n",
      "{'epoch': 0, 'batch': 160, 'loss': 9.18186092376709, 'perplexity': 9719.222686841236}\n",
      "{'epoch': 0, 'batch': 170, 'loss': 8.94586181640625, 'perplexity': 7676.0610956661285}\n",
      "{'epoch': 0, 'batch': 180, 'loss': 8.86295223236084, 'perplexity': 7065.310423435752}\n",
      "{'epoch': 0, 'batch': 190, 'loss': 8.988492012023926, 'perplexity': 8010.368243876164}\n",
      "{'epoch': 0, 'batch': 200, 'loss': 8.840547561645508, 'perplexity': 6908.7745848170425}\n",
      "{'epoch': 0, 'batch': 210, 'loss': 8.142266273498535, 'perplexity': 3436.6975457902736}\n",
      "{'epoch': 0, 'batch': 220, 'loss': 8.885302543640137, 'perplexity': 7225.000221514919}\n",
      "{'epoch': 0, 'batch': 230, 'loss': 8.796630859375, 'perplexity': 6611.929916041602}\n",
      "{'epoch': 0, 'batch': 240, 'loss': 8.792911529541016, 'perplexity': 6587.383643982203}\n",
      "{'epoch': 0, 'batch': 250, 'loss': 9.237054824829102, 'perplexity': 10270.74482698754}\n",
      "{'epoch': 0, 'batch': 260, 'loss': 8.236437797546387, 'perplexity': 3776.0652131441616}\n",
      "{'epoch': 0, 'batch': 270, 'loss': 9.218976974487305, 'perplexity': 10086.74005563479}\n",
      "{'epoch': 0, 'batch': 280, 'loss': 8.816559791564941, 'perplexity': 6745.0203896470275}\n",
      "{'epoch': 0, 'batch': 290, 'loss': 8.80538272857666, 'perplexity': 6670.050623270935}\n",
      "{'epoch': 0, 'batch': 300, 'loss': 8.702048301696777, 'perplexity': 6015.220593872235}\n",
      "{'epoch': 0, 'batch': 310, 'loss': 8.927033424377441, 'perplexity': 7532.885322637203}\n",
      "{'epoch': 0, 'batch': 320, 'loss': 9.216550827026367, 'perplexity': 10062.297799108295}\n",
      "{'epoch': 0, 'batch': 330, 'loss': 9.161877632141113, 'perplexity': 9526.928361367245}\n",
      "{'epoch': 0, 'batch': 340, 'loss': 8.505941390991211, 'perplexity': 4944.056321645418}\n",
      "{'epoch': 0, 'batch': 350, 'loss': 8.617558479309082, 'perplexity': 5527.873486874497}\n",
      "{'epoch': 0, 'batch': 360, 'loss': 8.40119743347168, 'perplexity': 4452.39500375376}\n",
      "{'epoch': 0, 'batch': 370, 'loss': 8.564497947692871, 'perplexity': 5242.207397592193}\n",
      "{'epoch': 0, 'batch': 380, 'loss': 8.638734817504883, 'perplexity': 5646.181853200527}\n",
      "{'epoch': 0, 'batch': 390, 'loss': 8.415316581726074, 'perplexity': 4515.704918198602}\n",
      "{'epoch': 0, 'batch': 400, 'loss': 8.594192504882812, 'perplexity': 5400.206674539345}\n",
      "{'epoch': 0, 'batch': 410, 'loss': 8.48155689239502, 'perplexity': 4824.955989551546}\n",
      "{'epoch': 0, 'batch': 420, 'loss': 8.50542163848877, 'perplexity': 4941.487303684622}\n",
      "{'epoch': 0, 'batch': 430, 'loss': 8.719876289367676, 'perplexity': 6123.421508906489}\n",
      "{'epoch': 0, 'batch': 440, 'loss': 8.648594856262207, 'perplexity': 5702.128791328726}\n",
      "{'epoch': 0, 'batch': 450, 'loss': 8.4398775100708, 'perplexity': 4627.988067907859}\n",
      "{'epoch': 0, 'batch': 460, 'loss': 8.327828407287598, 'perplexity': 4137.422991921086}\n",
      "{'epoch': 0, 'batch': 470, 'loss': 8.80936336517334, 'perplexity': 6696.654586108333}\n",
      "{'epoch': 0, 'batch': 480, 'loss': 8.498305320739746, 'perplexity': 4906.4469369467115}\n",
      "{'epoch': 0, 'batch': 490, 'loss': 8.340506553649902, 'perplexity': 4190.211771025769}\n",
      "{'epoch': 0, 'batch': 500, 'loss': 8.475287437438965, 'perplexity': 4794.800772471207}\n",
      "{'epoch': 0, 'batch': 510, 'loss': 8.60165023803711, 'perplexity': 5440.63052267545}\n",
      "{'epoch': 0, 'batch': 520, 'loss': 8.373276710510254, 'perplexity': 4329.800346197503}\n",
      "{'epoch': 0, 'batch': 530, 'loss': 8.13609790802002, 'perplexity': 3415.5639860575893}\n",
      "{'epoch': 0, 'batch': 540, 'loss': 8.959551811218262, 'perplexity': 7781.868934120953}\n",
      "{'epoch': 0, 'batch': 550, 'loss': 8.81301498413086, 'perplexity': 6721.152919012978}\n",
      "{'epoch': 0, 'batch': 560, 'loss': 8.222503662109375, 'perplexity': 3723.8138929555503}\n",
      "{'epoch': 0, 'batch': 570, 'loss': 8.560747146606445, 'perplexity': 5222.581749350038}\n",
      "{'epoch': 0, 'batch': 580, 'loss': 8.260560989379883, 'perplexity': 3868.2635466742927}\n",
      "{'epoch': 0, 'batch': 590, 'loss': 8.051495552062988, 'perplexity': 3138.4852312122525}\n",
      "{'epoch': 0, 'batch': 600, 'loss': 8.425576210021973, 'perplexity': 4562.272848503459}\n",
      "{'epoch': 0, 'batch': 610, 'loss': 8.737100601196289, 'perplexity': 6229.806807049672}\n",
      "{'epoch': 0, 'batch': 620, 'loss': 8.359235763549805, 'perplexity': 4269.43066474605}\n",
      "{'epoch': 0, 'batch': 630, 'loss': 8.477388381958008, 'perplexity': 4804.884972336975}\n",
      "{'epoch': 0, 'batch': 640, 'loss': 8.709446907043457, 'perplexity': 6059.889878559955}\n",
      "{'epoch': 0, 'batch': 650, 'loss': 8.50534439086914, 'perplexity': 4941.105600296015}\n",
      "{'epoch': 0, 'batch': 660, 'loss': 8.576095581054688, 'perplexity': 5303.358515693204}\n",
      "{'epoch': 0, 'batch': 670, 'loss': 8.585502624511719, 'perplexity': 5353.482830889387}\n",
      "{'epoch': 0, 'batch': 680, 'loss': 8.331558227539062, 'perplexity': 4152.88365080104}\n",
      "{'epoch': 0, 'batch': 690, 'loss': 8.542508125305176, 'perplexity': 5128.190389275788}\n",
      "{'epoch': 0, 'batch': 700, 'loss': 8.290247917175293, 'perplexity': 3984.8219778911593}\n",
      "{'epoch': 0, 'batch': 710, 'loss': 8.59194278717041, 'perplexity': 5388.0713895341}\n",
      "{'epoch': 0, 'batch': 720, 'loss': 8.636730194091797, 'perplexity': 5634.8747219196}\n",
      "{'epoch': 0, 'batch': 730, 'loss': 8.079246520996094, 'perplexity': 3226.800993639243}\n",
      "{'epoch': 0, 'batch': 740, 'loss': 8.303849220275879, 'perplexity': 4039.3910131593034}\n",
      "{'epoch': 0, 'batch': 750, 'loss': 8.153815269470215, 'perplexity': 3476.6180289391423}\n",
      "{'epoch': 0, 'batch': 760, 'loss': 8.468626022338867, 'perplexity': 4762.966761701503}\n",
      "{'epoch': 0, 'batch': 770, 'loss': 8.338464736938477, 'perplexity': 4181.6648551944145}\n",
      "{'epoch': 0, 'batch': 780, 'loss': 8.483613967895508, 'perplexity': 4834.891503856557}\n",
      "{'epoch': 0, 'batch': 790, 'loss': 8.30825424194336, 'perplexity': 4057.223866311926}\n",
      "{'epoch': 0, 'batch': 800, 'loss': 8.834182739257812, 'perplexity': 6864.941105800288}\n",
      "{'epoch': 0, 'batch': 810, 'loss': 8.509440422058105, 'perplexity': 4961.386029222983}\n",
      "{'epoch': 0, 'batch': 820, 'loss': 8.554161071777344, 'perplexity': 5188.298455241593}\n",
      "{'epoch': 0, 'batch': 830, 'loss': 8.474894523620605, 'perplexity': 4792.9171990566665}\n",
      "{'epoch': 0, 'batch': 840, 'loss': 8.629819869995117, 'perplexity': 5596.070141877321}\n",
      "{'epoch': 0, 'batch': 850, 'loss': 8.20377254486084, 'perplexity': 3654.711897489616}\n",
      "{'epoch': 0, 'batch': 860, 'loss': 8.421113014221191, 'perplexity': 4541.955904459983}\n",
      "{'epoch': 0, 'batch': 870, 'loss': 8.521126747131348, 'perplexity': 5019.706511496343}\n",
      "{'epoch': 0, 'batch': 880, 'loss': 7.6615729331970215, 'perplexity': 2125.097437390646}\n",
      "{'epoch': 0, 'batch': 890, 'loss': 8.639692306518555, 'perplexity': 5651.590599288417}\n",
      "{'epoch': 0, 'batch': 900, 'loss': 8.21678352355957, 'perplexity': 3702.5739671275587}\n",
      "{'epoch': 0, 'batch': 910, 'loss': 8.163457870483398, 'perplexity': 3510.303817770575}\n",
      "{'epoch': 0, 'batch': 920, 'loss': 7.917477130889893, 'perplexity': 2744.8374375312583}\n",
      "{'epoch': 0, 'batch': 930, 'loss': 8.566468238830566, 'perplexity': 5252.546254303846}\n",
      "{'epoch': 0, 'batch': 940, 'loss': 7.989353179931641, 'perplexity': 2949.3886186259515}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 950, 'loss': 7.726149082183838, 'perplexity': 2266.8558951904915}\n",
      "{'epoch': 0, 'batch': 960, 'loss': 8.147567749023438, 'perplexity': 3454.965494471167}\n",
      "{'epoch': 0, 'batch': 970, 'loss': 8.273262977600098, 'perplexity': 3917.7115639141994}\n",
      "{'epoch': 0, 'batch': 980, 'loss': 8.744501113891602, 'perplexity': 6276.081588773073}\n",
      "{'epoch': 0, 'batch': 990, 'loss': 8.36485481262207, 'perplexity': 4293.488332470524}\n",
      "{'epoch': 0, 'batch': 1000, 'loss': 8.096378326416016, 'perplexity': 3282.558167200096}\n",
      "{'epoch': 0, 'batch': 1010, 'loss': 8.31877613067627, 'perplexity': 4100.138902086716}\n",
      "{'epoch': 0, 'batch': 1020, 'loss': 8.293807983398438, 'perplexity': 3999.0334899721565}\n",
      "{'epoch': 0, 'batch': 1030, 'loss': 8.320867538452148, 'perplexity': 4108.722937699267}\n",
      "{'epoch': 0, 'batch': 1040, 'loss': 8.522899627685547, 'perplexity': 5028.613744955827}\n",
      "{'epoch': 0, 'batch': 1050, 'loss': 7.871315002441406, 'perplexity': 2621.0099575071927}\n",
      "{'epoch': 0, 'batch': 1060, 'loss': 8.135831832885742, 'perplexity': 3414.6553103047386}\n",
      "{'epoch': 0, 'batch': 1070, 'loss': 8.128735542297363, 'perplexity': 3390.5096974320063}\n",
      "{'epoch': 0, 'batch': 1080, 'loss': 8.160135269165039, 'perplexity': 3498.6598325502837}\n",
      "{'epoch': 0, 'batch': 1090, 'loss': 8.033955574035645, 'perplexity': 3083.9162377004013}\n",
      "{'epoch': 0, 'batch': 1100, 'loss': 8.446881294250488, 'perplexity': 4660.515271315023}\n",
      "{'epoch': 0, 'batch': 1110, 'loss': 8.593191146850586, 'perplexity': 5394.801840748603}\n",
      "{'epoch': 0, 'batch': 1120, 'loss': 8.189437866210938, 'perplexity': 3602.69647971777}\n",
      "{'epoch': 0, 'batch': 1130, 'loss': 7.904245376586914, 'perplexity': 2708.7576488066243}\n",
      "{'epoch': 0, 'batch': 1140, 'loss': 8.157878875732422, 'perplexity': 3490.7743791693747}\n",
      "{'epoch': 0, 'batch': 1150, 'loss': 8.042486190795898, 'perplexity': 3110.336475486921}\n",
      "{'epoch': 0, 'batch': 1160, 'loss': 8.133753776550293, 'perplexity': 3407.566831883389}\n",
      "{'epoch': 0, 'batch': 1170, 'loss': 8.440998077392578, 'perplexity': 4633.176946803435}\n",
      "{'epoch': 0, 'batch': 1180, 'loss': 8.27004337310791, 'perplexity': 3905.1183656011244}\n",
      "{'epoch': 0, 'batch': 1190, 'loss': 8.00767993927002, 'perplexity': 3003.939699468753}\n",
      "{'epoch': 0, 'batch': 1200, 'loss': 7.831806659698486, 'perplexity': 2519.477101824406}\n",
      "{'epoch': 0, 'batch': 1210, 'loss': 8.12296199798584, 'perplexity': 3370.990840168692}\n",
      "{'epoch': 0, 'batch': 1220, 'loss': 8.223949432373047, 'perplexity': 3729.2015660797642}\n",
      "{'epoch': 0, 'batch': 1230, 'loss': 8.331911087036133, 'perplexity': 4154.349293805272}\n",
      "{'epoch': 0, 'batch': 1240, 'loss': 8.41972827911377, 'perplexity': 4535.670851233937}\n",
      "{'epoch': 0, 'batch': 1250, 'loss': 8.00351333618164, 'perplexity': 2991.449513932193}\n",
      "{'epoch': 0, 'batch': 1260, 'loss': 8.092581748962402, 'perplexity': 3270.1193083589815}\n",
      "{'epoch': 0, 'batch': 1270, 'loss': 7.976205348968506, 'perplexity': 2910.8643657637595}\n",
      "{'epoch': 0, 'batch': 1280, 'loss': 8.149761199951172, 'perplexity': 3462.5521091320447}\n",
      "{'epoch': 0, 'batch': 1290, 'loss': 7.9790263175964355, 'perplexity': 2919.0874158497377}\n",
      "{'epoch': 0, 'batch': 1300, 'loss': 7.923105239868164, 'perplexity': 2760.3292356286456}\n",
      "{'epoch': 0, 'batch': 1310, 'loss': 8.036767959594727, 'perplexity': 3092.601606771251}\n",
      "{'epoch': 0, 'batch': 1320, 'loss': 8.358362197875977, 'perplexity': 4265.702665233816}\n",
      "{'epoch': 0, 'batch': 1330, 'loss': 8.173563003540039, 'perplexity': 3545.9557352245524}\n",
      "{'epoch': 0, 'batch': 1340, 'loss': 8.49716567993164, 'perplexity': 4900.858534784983}\n",
      "{'epoch': 0, 'batch': 1350, 'loss': 8.043022155761719, 'perplexity': 3112.003953684726}\n",
      "{'epoch': 0, 'batch': 1360, 'loss': 8.327093124389648, 'perplexity': 4134.381933709601}\n",
      "{'epoch': 0, 'batch': 1370, 'loss': 7.938922882080078, 'perplexity': 2804.338277930862}\n",
      "{'epoch': 0, 'batch': 1380, 'loss': 8.031132698059082, 'perplexity': 3075.223000377429}\n",
      "{'epoch': 0, 'batch': 1390, 'loss': 8.3878173828125, 'perplexity': 4393.218508143838}\n",
      "{'epoch': 0, 'batch': 1400, 'loss': 8.25156307220459, 'perplexity': 3833.6133552257274}\n",
      "{'epoch': 0, 'batch': 1410, 'loss': 8.02613639831543, 'perplexity': 3059.896584056715}\n",
      "{'epoch': 0, 'batch': 1420, 'loss': 8.067950248718262, 'perplexity': 3190.5552771990074}\n",
      "{'epoch': 0, 'batch': 1430, 'loss': 8.052663803100586, 'perplexity': 3142.1539123931448}\n",
      "{'epoch': 0, 'batch': 1440, 'loss': 8.322742462158203, 'perplexity': 4116.433706029107}\n",
      "{'epoch': 0, 'batch': 1450, 'loss': 8.325883865356445, 'perplexity': 4129.3854166601095}\n",
      "{'epoch': 0, 'batch': 1460, 'loss': 7.98677921295166, 'perplexity': 2941.806751634135}\n",
      "{'epoch': 0, 'batch': 1470, 'loss': 7.550897121429443, 'perplexity': 1902.4486934889067}\n",
      "{'epoch': 0, 'batch': 1480, 'loss': 8.423063278198242, 'perplexity': 4550.8225607956465}\n",
      "{'epoch': 0, 'batch': 1490, 'loss': 7.958366870880127, 'perplexity': 2859.3993688877795}\n",
      "{'epoch': 0, 'batch': 1500, 'loss': 8.272625923156738, 'perplexity': 3915.216563164645}\n",
      "{'epoch': 0, 'batch': 1510, 'loss': 7.765650749206543, 'perplexity': 2358.1925812653235}\n",
      "{'epoch': 0, 'batch': 1520, 'loss': 8.091374397277832, 'perplexity': 3266.173506767703}\n",
      "{'epoch': 0, 'batch': 1530, 'loss': 8.041548728942871, 'perplexity': 3107.4220199999368}\n",
      "{'epoch': 0, 'batch': 1540, 'loss': 7.862442970275879, 'perplexity': 2597.8591221915}\n",
      "{'epoch': 0, 'batch': 1550, 'loss': 8.07540225982666, 'perplexity': 3214.4201407412975}\n",
      "{'epoch': 0, 'batch': 1560, 'loss': 7.910834789276123, 'perplexity': 2726.6657078275216}\n",
      "{'epoch': 0, 'batch': 1570, 'loss': 8.030816078186035, 'perplexity': 3074.2494777878906}\n",
      "{'epoch': 0, 'batch': 1580, 'loss': 8.11518669128418, 'perplexity': 3344.881986206442}\n",
      "{'epoch': 0, 'batch': 1590, 'loss': 7.4976043701171875, 'perplexity': 1803.7161980942258}\n",
      "{'epoch': 0, 'batch': 1600, 'loss': 8.23751163482666, 'perplexity': 3780.122270662727}\n",
      "{'epoch': 0, 'batch': 1610, 'loss': 7.744540691375732, 'perplexity': 2308.9327675658774}\n",
      "{'epoch': 0, 'batch': 1620, 'loss': 7.940834045410156, 'perplexity': 2809.7029511632654}\n",
      "{'epoch': 0, 'batch': 1630, 'loss': 8.13815975189209, 'perplexity': 3422.6136108472956}\n",
      "{'epoch': 0, 'batch': 1640, 'loss': 8.183378219604492, 'perplexity': 3580.9314230959385}\n",
      "{'epoch': 0, 'batch': 1650, 'loss': 8.078627586364746, 'perplexity': 3224.804432689907}\n",
      "{'epoch': 0, 'batch': 1660, 'loss': 7.812366485595703, 'perplexity': 2470.971039078844}\n",
      "{'epoch': 0, 'batch': 1670, 'loss': 8.076108932495117, 'perplexity': 3216.69248640742}\n",
      "{'epoch': 0, 'batch': 1680, 'loss': 7.466121196746826, 'perplexity': 1747.8140935354234}\n",
      "{'epoch': 0, 'batch': 1690, 'loss': 8.282145500183105, 'perplexity': 3952.6657361454136}\n",
      "{'epoch': 0, 'batch': 1700, 'loss': 7.785000324249268, 'perplexity': 2404.266927558405}\n",
      "{'epoch': 0, 'batch': 1710, 'loss': 8.05417251586914, 'perplexity': 3146.89809802836}\n",
      "{'epoch': 0, 'batch': 1720, 'loss': 7.769664287567139, 'perplexity': 2367.6762965487583}\n",
      "{'epoch': 0, 'batch': 1730, 'loss': 7.704167366027832, 'perplexity': 2217.570189075087}\n",
      "{'epoch': 0, 'batch': 1740, 'loss': 7.886383533477783, 'perplexity': 2660.8037917467923}\n",
      "{'epoch': 0, 'batch': 1750, 'loss': 7.643151760101318, 'perplexity': 2086.30901067716}\n",
      "{'epoch': 0, 'batch': 1760, 'loss': 7.999190807342529, 'perplexity': 2978.546793418043}\n",
      "{'epoch': 0, 'batch': 1770, 'loss': 8.304543495178223, 'perplexity': 4042.1964347146923}\n",
      "{'epoch': 0, 'batch': 1780, 'loss': 7.865628242492676, 'perplexity': 2606.1472035666925}\n",
      "{'epoch': 0, 'batch': 1790, 'loss': 7.811182975769043, 'perplexity': 2468.0483504292197}\n",
      "{'epoch': 0, 'batch': 1800, 'loss': 7.687539100646973, 'perplexity': 2181.0007294254165}\n",
      "{'epoch': 0, 'batch': 1810, 'loss': 8.61262035369873, 'perplexity': 5500.643441264868}\n",
      "{'epoch': 0, 'batch': 1820, 'loss': 7.864744186401367, 'perplexity': 2603.844241380398}\n",
      "{'epoch': 0, 'batch': 1830, 'loss': 8.104287147521973, 'perplexity': 3308.622264799204}\n",
      "{'epoch': 0, 'batch': 1840, 'loss': 7.778658866882324, 'perplexity': 2389.068612005762}\n",
      "{'epoch': 0, 'batch': 1850, 'loss': 8.147333145141602, 'perplexity': 3454.155041226011}\n",
      "{'epoch': 0, 'batch': 1860, 'loss': 7.846409320831299, 'perplexity': 2556.5381082687236}\n",
      "{'epoch': 0, 'batch': 1870, 'loss': 7.789748668670654, 'perplexity': 2415.7103621948727}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 1880, 'loss': 7.6862945556640625, 'perplexity': 2178.2880642769223}\n",
      "{'epoch': 0, 'batch': 1890, 'loss': 7.96051025390625, 'perplexity': 2865.5347298253396}\n",
      "{'epoch': 0, 'batch': 1900, 'loss': 7.747730255126953, 'perplexity': 2316.3090130745527}\n",
      "{'epoch': 0, 'batch': 1910, 'loss': 7.624538421630859, 'perplexity': 2047.8350104917922}\n",
      "{'epoch': 0, 'batch': 1920, 'loss': 7.65710973739624, 'perplexity': 2115.6338460719985}\n",
      "{'epoch': 0, 'batch': 1930, 'loss': 7.879726409912109, 'perplexity': 2643.149321316506}\n",
      "{'epoch': 0, 'batch': 1940, 'loss': 7.741633415222168, 'perplexity': 2302.2298107850106}\n",
      "{'epoch': 0, 'batch': 1950, 'loss': 8.12581729888916, 'perplexity': 3380.6297878590794}\n",
      "{'epoch': 0, 'batch': 1960, 'loss': 7.917121410369873, 'perplexity': 2743.8612161718897}\n",
      "{'epoch': 0, 'batch': 1970, 'loss': 7.886530876159668, 'perplexity': 2661.1958705977027}\n",
      "{'epoch': 0, 'batch': 1980, 'loss': 7.641680717468262, 'perplexity': 2083.242217421573}\n",
      "{'epoch': 0, 'batch': 1990, 'loss': 7.937345504760742, 'perplexity': 2799.918265265833}\n",
      "{'epoch': 0, 'batch': 2000, 'loss': 7.829559326171875, 'perplexity': 2513.8213540201423}\n",
      "{'epoch': 0, 'batch': 2010, 'loss': 7.797131538391113, 'perplexity': 2433.611235679913}\n",
      "{'epoch': 0, 'batch': 2020, 'loss': 8.423527717590332, 'perplexity': 4552.936632950483}\n",
      "{'epoch': 0, 'batch': 2030, 'loss': 7.971491813659668, 'perplexity': 2897.1761889917407}\n",
      "{'epoch': 0, 'batch': 2040, 'loss': 7.856126308441162, 'perplexity': 2581.5010432397553}\n",
      "{'epoch': 0, 'batch': 2050, 'loss': 7.57170295715332, 'perplexity': 1942.4453677838949}\n",
      "{'epoch': 0, 'batch': 2060, 'loss': 7.744131565093994, 'perplexity': 2307.988315701113}\n",
      "{'epoch': 0, 'batch': 2070, 'loss': 7.792407512664795, 'perplexity': 2422.1419056293385}\n",
      "{'epoch': 0, 'batch': 2080, 'loss': 7.786032199859619, 'perplexity': 2406.749112394478}\n",
      "{'epoch': 0, 'batch': 2090, 'loss': 7.419558525085449, 'perplexity': 1668.2968339430051}\n",
      "{'epoch': 0, 'batch': 2100, 'loss': 7.778902530670166, 'perplexity': 2389.6508124408783}\n",
      "{'epoch': 0, 'batch': 2110, 'loss': 8.217155456542969, 'perplexity': 3703.9513326373594}\n",
      "{'epoch': 0, 'batch': 2120, 'loss': 8.018095970153809, 'perplexity': 3035.3923496720568}\n",
      "{'epoch': 0, 'batch': 2130, 'loss': 7.533195972442627, 'perplexity': 1869.0694626516042}\n",
      "{'epoch': 0, 'batch': 2140, 'loss': 7.900683879852295, 'perplexity': 2699.127576200787}\n",
      "{'epoch': 0, 'batch': 2150, 'loss': 7.83080530166626, 'perplexity': 2516.955465932368}\n",
      "{'epoch': 0, 'batch': 2160, 'loss': 7.8386006355285645, 'perplexity': 2536.6526474135976}\n",
      "{'epoch': 0, 'batch': 2170, 'loss': 7.938867568969727, 'perplexity': 2804.1831655481456}\n",
      "{'epoch': 0, 'batch': 2180, 'loss': 7.717553615570068, 'perplexity': 2247.4547115878986}\n",
      "{'epoch': 0, 'batch': 2190, 'loss': 7.838902950286865, 'perplexity': 2537.419630874962}\n",
      "{'epoch': 0, 'batch': 2200, 'loss': 7.700382232666016, 'perplexity': 2209.1922559700142}\n",
      "{'epoch': 0, 'batch': 2210, 'loss': 7.9015092849731445, 'perplexity': 2701.3563696262245}\n",
      "{'epoch': 0, 'batch': 2220, 'loss': 7.785436153411865, 'perplexity': 2405.315005574996}\n",
      "{'epoch': 0, 'batch': 2230, 'loss': 7.632082939147949, 'perplexity': 2063.3433655679264}\n",
      "{'epoch': 0, 'batch': 2240, 'loss': 7.750568389892578, 'perplexity': 2322.8923479892696}\n",
      "{'epoch': 0, 'batch': 2250, 'loss': 8.115580558776855, 'perplexity': 3346.199685970162}\n",
      "{'epoch': 0, 'batch': 2260, 'loss': 7.835180759429932, 'perplexity': 2527.9924265358727}\n",
      "{'epoch': 0, 'batch': 2270, 'loss': 7.356928825378418, 'perplexity': 1567.016583683849}\n",
      "{'epoch': 0, 'batch': 2280, 'loss': 7.694919109344482, 'perplexity': 2197.156073744276}\n",
      "{'epoch': 0, 'batch': 2290, 'loss': 7.845184803009033, 'perplexity': 2553.4094977024774}\n",
      "{'epoch': 0, 'batch': 2300, 'loss': 7.4976067543029785, 'perplexity': 1803.7204984938828}\n",
      "{'epoch': 0, 'batch': 2310, 'loss': 7.900776386260986, 'perplexity': 2699.377274348623}\n",
      "{'epoch': 0, 'batch': 2320, 'loss': 7.760841369628906, 'perplexity': 2346.8783670086073}\n",
      "{'epoch': 0, 'batch': 2330, 'loss': 7.544114589691162, 'perplexity': 1889.588935003539}\n",
      "{'epoch': 0, 'batch': 2340, 'loss': 7.586669921875, 'perplexity': 1971.7365321986824}\n",
      "{'epoch': 0, 'batch': 2350, 'loss': 7.976163864135742, 'perplexity': 2910.7436115470996}\n",
      "{'epoch': 0, 'batch': 2360, 'loss': 7.635605812072754, 'perplexity': 2070.625080792877}\n",
      "{'epoch': 0, 'batch': 2370, 'loss': 7.887759208679199, 'perplexity': 2664.4667124558564}\n",
      "{'epoch': 0, 'batch': 2380, 'loss': 7.574454307556152, 'perplexity': 1947.7970744631873}\n",
      "{'epoch': 0, 'batch': 2390, 'loss': 7.732539653778076, 'perplexity': 2281.3887873669673}\n",
      "{'epoch': 0, 'batch': 2400, 'loss': 7.537596225738525, 'perplexity': 1877.311962960047}\n",
      "{'epoch': 0, 'batch': 2410, 'loss': 7.485269069671631, 'perplexity': 1781.6034807660478}\n",
      "{'epoch': 0, 'batch': 2420, 'loss': 8.010038375854492, 'perplexity': 3011.0326616165216}\n",
      "{'epoch': 0, 'batch': 2430, 'loss': 7.921459674835205, 'perplexity': 2755.7906696359487}\n",
      "{'epoch': 0, 'batch': 2440, 'loss': 7.604010581970215, 'perplexity': 2006.2259152976696}\n",
      "{'epoch': 0, 'batch': 2450, 'loss': 7.466744422912598, 'perplexity': 1748.9037165169268}\n",
      "{'epoch': 0, 'batch': 2460, 'loss': 7.914748191833496, 'perplexity': 2737.357154704705}\n",
      "{'epoch': 0, 'batch': 2470, 'loss': 7.695303440093994, 'perplexity': 2198.0006706767817}\n",
      "{'epoch': 0, 'batch': 2480, 'loss': 7.23132848739624, 'perplexity': 1382.0573307899601}\n",
      "{'epoch': 0, 'batch': 2490, 'loss': 8.002440452575684, 'perplexity': 2988.2417578727895}\n",
      "{'epoch': 0, 'batch': 2500, 'loss': 7.8005876541137695, 'perplexity': 2442.0366289148037}\n",
      "{'epoch': 0, 'batch': 2510, 'loss': 8.074824333190918, 'perplexity': 3212.5629784269718}\n",
      "{'epoch': 0, 'batch': 2520, 'loss': 8.197940826416016, 'perplexity': 3633.4606725144413}\n",
      "{'epoch': 0, 'batch': 2530, 'loss': 7.624302387237549, 'perplexity': 2047.3517080377353}\n",
      "{'epoch': 0, 'batch': 2540, 'loss': 7.901196002960205, 'perplexity': 2700.5102158143864}\n",
      "{'epoch': 0, 'batch': 2550, 'loss': 7.4931464195251465, 'perplexity': 1795.6932167152895}\n",
      "{'epoch': 0, 'batch': 2560, 'loss': 7.532138347625732, 'perplexity': 1867.0937333777258}\n",
      "{'epoch': 0, 'batch': 2570, 'loss': 7.768843650817871, 'perplexity': 2365.734091400898}\n",
      "{'epoch': 0, 'batch': 2580, 'loss': 7.539440155029297, 'perplexity': 1880.776786939955}\n",
      "{'epoch': 0, 'batch': 2590, 'loss': 7.492791175842285, 'perplexity': 1795.0554213367914}\n",
      "{'epoch': 0, 'batch': 2600, 'loss': 7.976545333862305, 'perplexity': 2911.854183928094}\n",
      "{'epoch': 0, 'batch': 2610, 'loss': 7.435227394104004, 'perplexity': 1694.6430270157873}\n",
      "{'epoch': 0, 'batch': 2620, 'loss': 7.542530059814453, 'perplexity': 1886.597195757392}\n",
      "{'epoch': 0, 'batch': 2630, 'loss': 7.8556084632873535, 'perplexity': 2580.164571507533}\n",
      "{'epoch': 0, 'batch': 2640, 'loss': 7.703830242156982, 'perplexity': 2216.8227192311083}\n",
      "{'epoch': 0, 'batch': 2650, 'loss': 7.7736687660217285, 'perplexity': 2377.176614479496}\n",
      "{'epoch': 0, 'batch': 2660, 'loss': 8.16344165802002, 'perplexity': 3510.2469075598087}\n",
      "{'epoch': 0, 'batch': 2670, 'loss': 7.470300197601318, 'perplexity': 1755.133493362675}\n",
      "{'epoch': 0, 'batch': 2680, 'loss': 7.699422836303711, 'perplexity': 2207.0737813469227}\n",
      "{'epoch': 0, 'batch': 2690, 'loss': 7.319586277008057, 'perplexity': 1509.5792928889505}\n",
      "{'epoch': 0, 'batch': 2700, 'loss': 7.28542423248291, 'perplexity': 1458.8799058407274}\n",
      "{'epoch': 0, 'batch': 2710, 'loss': 7.893588542938232, 'perplexity': 2680.0441384447913}\n",
      "{'epoch': 0, 'batch': 2720, 'loss': 7.665496826171875, 'perplexity': 2133.4524737101015}\n",
      "{'epoch': 0, 'batch': 2730, 'loss': 7.7366132736206055, 'perplexity': 2290.7012528439063}\n",
      "{'epoch': 0, 'batch': 2740, 'loss': 7.612412452697754, 'perplexity': 2023.1529760008148}\n",
      "{'epoch': 0, 'batch': 2750, 'loss': 8.098936080932617, 'perplexity': 3290.9648917639793}\n",
      "{'epoch': 0, 'batch': 2760, 'loss': 7.197856426239014, 'perplexity': 1336.5626708364705}\n",
      "{'epoch': 0, 'batch': 2770, 'loss': 7.893787860870361, 'perplexity': 2680.578372539929}\n",
      "{'epoch': 0, 'batch': 2780, 'loss': 7.761355400085449, 'perplexity': 2348.085044074863}\n",
      "{'epoch': 0, 'batch': 2790, 'loss': 7.6330485343933105, 'perplexity': 2065.3366823249817}\n",
      "{'epoch': 0, 'batch': 2800, 'loss': 7.90204381942749, 'perplexity': 2702.8007236733665}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 2810, 'loss': 7.635678768157959, 'perplexity': 2070.7761510033774}\n",
      "{'epoch': 0, 'batch': 2820, 'loss': 8.004242897033691, 'perplexity': 2993.6327546951024}\n",
      "{'epoch': 0, 'batch': 2830, 'loss': 7.556046009063721, 'perplexity': 1912.2694493292804}\n",
      "{'epoch': 0, 'batch': 2840, 'loss': 7.331290245056152, 'perplexity': 1527.3511585030103}\n",
      "{'epoch': 0, 'batch': 2850, 'loss': 7.8025288581848145, 'perplexity': 2446.781724469831}\n",
      "{'epoch': 0, 'batch': 2860, 'loss': 7.720390796661377, 'perplexity': 2253.840201711723}\n",
      "{'epoch': 0, 'batch': 2870, 'loss': 7.7013020515441895, 'perplexity': 2211.2252475612563}\n",
      "{'epoch': 0, 'batch': 2880, 'loss': 7.668887615203857, 'perplexity': 2140.6988394640807}\n",
      "{'epoch': 0, 'batch': 2890, 'loss': 7.5691752433776855, 'perplexity': 1937.5416221130452}\n",
      "{'epoch': 0, 'batch': 2900, 'loss': 7.798945426940918, 'perplexity': 2438.0295411804445}\n",
      "{'epoch': 0, 'batch': 2910, 'loss': 7.586371421813965, 'perplexity': 1971.1480565578527}\n",
      "{'epoch': 0, 'batch': 2920, 'loss': 7.783939838409424, 'perplexity': 2401.718588004359}\n",
      "{'epoch': 0, 'batch': 2930, 'loss': 7.441600322723389, 'perplexity': 1705.477352585095}\n",
      "{'epoch': 0, 'batch': 2940, 'loss': 7.64206075668335, 'perplexity': 2084.034081618913}\n",
      "{'epoch': 0, 'batch': 2950, 'loss': 7.604763507843018, 'perplexity': 2007.737023500829}\n",
      "{'epoch': 0, 'batch': 2960, 'loss': 7.964585781097412, 'perplexity': 2877.2371250509495}\n",
      "{'epoch': 0, 'batch': 2970, 'loss': 7.959853172302246, 'perplexity': 2863.65245813951}\n",
      "{'epoch': 0, 'batch': 2980, 'loss': 7.303786277770996, 'perplexity': 1485.9153784145483}\n",
      "{'epoch': 0, 'batch': 2990, 'loss': 7.87150239944458, 'perplexity': 2621.501172943231}\n",
      "{'epoch': 0, 'batch': 3000, 'loss': 7.582210540771484, 'perplexity': 1962.9633835112447}\n",
      "{'epoch': 0, 'batch': 3010, 'loss': 7.519662380218506, 'perplexity': 1843.9446367631408}\n",
      "{'epoch': 0, 'batch': 3020, 'loss': 7.7735419273376465, 'perplexity': 2376.8751156471467}\n",
      "{'epoch': 0, 'batch': 3030, 'loss': 7.438529968261719, 'perplexity': 1700.2489631980177}\n",
      "{'epoch': 0, 'batch': 3040, 'loss': 7.789824485778809, 'perplexity': 2415.8935213118825}\n",
      "{'epoch': 0, 'batch': 3050, 'loss': 7.609814167022705, 'perplexity': 2017.903069936249}\n",
      "{'epoch': 0, 'batch': 3060, 'loss': 7.383638858795166, 'perplexity': 1609.4356342536842}\n",
      "{'epoch': 0, 'batch': 3070, 'loss': 7.883565902709961, 'perplexity': 2653.3171813210124}\n",
      "{'epoch': 0, 'batch': 3080, 'loss': 7.31270170211792, 'perplexity': 1499.2221742821216}\n",
      "{'epoch': 0, 'batch': 3090, 'loss': 7.321457386016846, 'perplexity': 1512.406524507776}\n",
      "{'epoch': 0, 'batch': 3100, 'loss': 7.305582523345947, 'perplexity': 1488.5868459253345}\n",
      "{'epoch': 0, 'batch': 3110, 'loss': 8.109389305114746, 'perplexity': 3325.5465153916575}\n",
      "{'epoch': 0, 'batch': 3120, 'loss': 7.134092330932617, 'perplexity': 1253.9982566148599}\n",
      "{'epoch': 0, 'batch': 3130, 'loss': 7.248716354370117, 'perplexity': 1406.2985001732927}\n",
      "{'epoch': 0, 'batch': 3140, 'loss': 7.071533679962158, 'perplexity': 1177.9532528818058}\n",
      "{'epoch': 0, 'batch': 3150, 'loss': 7.787801742553711, 'perplexity': 2411.0117280307186}\n",
      "{'epoch': 0, 'batch': 3160, 'loss': 7.690253734588623, 'perplexity': 2186.9293914650702}\n",
      "{'epoch': 0, 'batch': 3170, 'loss': 7.70846700668335, 'perplexity': 2227.125471436123}\n",
      "{'epoch': 0, 'batch': 3180, 'loss': 7.642795562744141, 'perplexity': 2085.5660052574403}\n",
      "{'epoch': 0, 'batch': 3190, 'loss': 7.60015344619751, 'perplexity': 1998.5025341918006}\n",
      "{'epoch': 0, 'batch': 3200, 'loss': 7.36151647567749, 'perplexity': 1574.2220231634722}\n",
      "{'epoch': 0, 'batch': 3210, 'loss': 7.910672664642334, 'perplexity': 2726.22368398062}\n",
      "{'epoch': 0, 'batch': 3220, 'loss': 7.52688455581665, 'perplexity': 1857.3101346142062}\n",
      "{'epoch': 0, 'batch': 3230, 'loss': 7.793817043304443, 'perplexity': 2425.5583961172606}\n",
      "{'epoch': 0, 'batch': 3240, 'loss': 7.494852542877197, 'perplexity': 1798.7595058353886}\n",
      "{'epoch': 0, 'batch': 3250, 'loss': 7.818042278289795, 'perplexity': 2485.0356345567734}\n",
      "{'epoch': 0, 'batch': 3260, 'loss': 7.231419086456299, 'perplexity': 1382.1825495573423}\n",
      "{'epoch': 0, 'batch': 3270, 'loss': 7.730340957641602, 'perplexity': 2276.378217033739}\n",
      "{'epoch': 0, 'batch': 3280, 'loss': 7.341673374176025, 'perplexity': 1543.292459870137}\n",
      "{'epoch': 0, 'batch': 3290, 'loss': 7.787856101989746, 'perplexity': 2411.1427928308003}\n",
      "{'epoch': 0, 'batch': 3300, 'loss': 7.473372459411621, 'perplexity': 1760.534014626067}\n",
      "{'epoch': 0, 'batch': 3310, 'loss': 7.001211643218994, 'perplexity': 1097.9626918560184}\n",
      "{'epoch': 0, 'batch': 3320, 'loss': 7.20258092880249, 'perplexity': 1342.8922047773326}\n",
      "{'epoch': 0, 'batch': 3330, 'loss': 7.352498531341553, 'perplexity': 1560.0895950855806}\n",
      "{'epoch': 0, 'batch': 3340, 'loss': 7.106494426727295, 'perplexity': 1219.8637201921097}\n",
      "{'epoch': 0, 'batch': 3350, 'loss': 7.411993026733398, 'perplexity': 1655.7229607773631}\n",
      "{'epoch': 0, 'batch': 3360, 'loss': 7.594130039215088, 'perplexity': 1986.5009216576163}\n",
      "{'epoch': 0, 'batch': 3370, 'loss': 7.428670883178711, 'perplexity': 1683.5684265369334}\n",
      "{'epoch': 0, 'batch': 3380, 'loss': 7.358767032623291, 'perplexity': 1569.899734022885}\n",
      "{'epoch': 0, 'batch': 3390, 'loss': 7.295668601989746, 'perplexity': 1473.9020253567048}\n",
      "{'epoch': 0, 'batch': 3400, 'loss': 7.374563217163086, 'perplexity': 1594.895055553513}\n",
      "{'epoch': 0, 'batch': 3410, 'loss': 7.609009742736816, 'perplexity': 2016.280472416147}\n",
      "{'epoch': 0, 'batch': 3420, 'loss': 6.794659614562988, 'perplexity': 893.0652214636879}\n",
      "{'epoch': 0, 'batch': 3430, 'loss': 7.433709621429443, 'perplexity': 1692.0728950676555}\n",
      "{'epoch': 0, 'batch': 3440, 'loss': 7.282255172729492, 'perplexity': 1454.2639462351117}\n",
      "{'epoch': 0, 'batch': 3450, 'loss': 7.205051898956299, 'perplexity': 1346.2145543580095}\n",
      "{'epoch': 0, 'batch': 3460, 'loss': 6.951430797576904, 'perplexity': 1044.6433325516828}\n",
      "{'epoch': 0, 'batch': 3470, 'loss': 7.090751647949219, 'perplexity': 1200.8100478921024}\n",
      "{'epoch': 0, 'batch': 3480, 'loss': 7.165263652801514, 'perplexity': 1293.7026441672276}\n",
      "{'epoch': 0, 'batch': 3490, 'loss': 7.387567043304443, 'perplexity': 1615.7702279617126}\n",
      "{'epoch': 0, 'batch': 3500, 'loss': 7.279526233673096, 'perplexity': 1450.300758662123}\n",
      "{'epoch': 0, 'batch': 3510, 'loss': 6.776148796081543, 'perplexity': 876.6859181079511}\n",
      "{'epoch': 0, 'batch': 3520, 'loss': 7.554570198059082, 'perplexity': 1909.4493824868123}\n",
      "{'epoch': 0, 'batch': 3530, 'loss': 7.867549419403076, 'perplexity': 2611.1588860221204}\n",
      "{'epoch': 0, 'batch': 3540, 'loss': 7.243810653686523, 'perplexity': 1399.4165149412424}\n",
      "{'epoch': 0, 'batch': 3550, 'loss': 7.56439733505249, 'perplexity': 1928.3063061817325}\n",
      "{'epoch': 0, 'batch': 3560, 'loss': 7.358707427978516, 'perplexity': 1569.8061634955523}\n",
      "{'epoch': 0, 'batch': 3570, 'loss': 7.174701690673828, 'perplexity': 1305.9704597078016}\n",
      "{'epoch': 0, 'batch': 3580, 'loss': 7.468390941619873, 'perplexity': 1751.7856911648896}\n",
      "{'epoch': 0, 'batch': 3590, 'loss': 7.292181491851807, 'perplexity': 1468.7713175324775}\n",
      "{'epoch': 0, 'batch': 3600, 'loss': 7.296665668487549, 'perplexity': 1475.3723365644466}\n",
      "{'epoch': 0, 'batch': 3610, 'loss': 7.313616752624512, 'perplexity': 1500.5946661461123}\n",
      "{'epoch': 0, 'batch': 3620, 'loss': 7.332155227661133, 'perplexity': 1528.6728622297708}\n",
      "{'epoch': 0, 'batch': 3630, 'loss': 7.079946041107178, 'perplexity': 1187.9044187725176}\n",
      "{'epoch': 0, 'batch': 3640, 'loss': 7.138817310333252, 'perplexity': 1259.937392644018}\n",
      "{'epoch': 0, 'batch': 3650, 'loss': 6.8504533767700195, 'perplexity': 944.3089373705843}\n",
      "{'epoch': 0, 'batch': 3660, 'loss': 7.055513858795166, 'perplexity': 1159.2330003303744}\n",
      "{'epoch': 0, 'batch': 3670, 'loss': 7.554096221923828, 'perplexity': 1908.5445634962816}\n",
      "{'epoch': 0, 'batch': 3680, 'loss': 7.11142110824585, 'perplexity': 1225.888428962143}\n",
      "{'epoch': 0, 'batch': 3690, 'loss': 7.163334846496582, 'perplexity': 1291.209747280926}\n",
      "{'epoch': 0, 'batch': 3700, 'loss': 7.225035190582275, 'perplexity': 1373.3869450651011}\n",
      "{'epoch': 0, 'batch': 3710, 'loss': 7.328380584716797, 'perplexity': 1522.9135445183335}\n",
      "{'epoch': 0, 'batch': 3720, 'loss': 7.1257500648498535, 'perplexity': 1243.5805834084902}\n",
      "{'epoch': 0, 'batch': 3730, 'loss': 7.663326740264893, 'perplexity': 2128.8277184367435}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 3740, 'loss': 7.160329818725586, 'perplexity': 1287.3354502327475}\n",
      "{'epoch': 0, 'batch': 3750, 'loss': 7.251073837280273, 'perplexity': 1409.6177358374227}\n",
      "{'epoch': 0, 'batch': 3760, 'loss': 7.13455867767334, 'perplexity': 1254.5831909952242}\n",
      "{'epoch': 0, 'batch': 3770, 'loss': 7.7371931076049805, 'perplexity': 2292.0298644282057}\n",
      "{'epoch': 0, 'batch': 3780, 'loss': 6.870387077331543, 'perplexity': 963.321373521333}\n",
      "{'epoch': 0, 'batch': 3790, 'loss': 7.478954315185547, 'perplexity': 1770.3885392618868}\n",
      "{'epoch': 0, 'batch': 3800, 'loss': 7.35610294342041, 'perplexity': 1565.72294722852}\n",
      "{'epoch': 0, 'batch': 3810, 'loss': 7.152223587036133, 'perplexity': 1276.9421928000359}\n",
      "{'epoch': 0, 'batch': 3820, 'loss': 7.289883136749268, 'perplexity': 1465.399435855405}\n",
      "{'epoch': 0, 'batch': 3830, 'loss': 7.3074541091918945, 'perplexity': 1491.3754727598803}\n",
      "{'epoch': 0, 'batch': 3840, 'loss': 7.264123916625977, 'perplexity': 1428.1339151601298}\n",
      "{'epoch': 0, 'batch': 3850, 'loss': 7.136585712432861, 'perplexity': 1257.1288539340646}\n",
      "{'epoch': 0, 'batch': 3860, 'loss': 7.334686279296875, 'perplexity': 1532.5469128211062}\n",
      "{'epoch': 0, 'batch': 3870, 'loss': 7.134145259857178, 'perplexity': 1254.0646311505343}\n",
      "{'epoch': 0, 'batch': 3880, 'loss': 7.075109481811523, 'perplexity': 1182.1729201527614}\n",
      "{'epoch': 0, 'batch': 3890, 'loss': 6.673649311065674, 'perplexity': 791.2779613758076}\n",
      "{'epoch': 0, 'batch': 3900, 'loss': 7.5846076011657715, 'perplexity': 1967.67436929628}\n",
      "{'epoch': 0, 'batch': 3910, 'loss': 7.492147922515869, 'perplexity': 1793.9011172606856}\n",
      "{'epoch': 0, 'batch': 3920, 'loss': 6.595051288604736, 'perplexity': 731.4664016193676}\n",
      "{'epoch': 0, 'batch': 3930, 'loss': 7.168741226196289, 'perplexity': 1298.2094218465127}\n",
      "{'epoch': 0, 'batch': 3940, 'loss': 7.343141078948975, 'perplexity': 1545.5592206404326}\n",
      "{'epoch': 0, 'batch': 3950, 'loss': 7.171895503997803, 'perplexity': 1302.3108000501268}\n",
      "{'epoch': 0, 'batch': 3960, 'loss': 6.8492889404296875, 'perplexity': 943.2099896788969}\n",
      "{'epoch': 0, 'batch': 3970, 'loss': 7.322829246520996, 'perplexity': 1514.4827591114697}\n",
      "{'epoch': 0, 'batch': 3980, 'loss': 7.154204845428467, 'perplexity': 1279.474653136787}\n",
      "{'epoch': 0, 'batch': 3990, 'loss': 6.813976287841797, 'perplexity': 910.4839650289982}\n",
      "{'epoch': 0, 'batch': 4000, 'loss': 7.115396976470947, 'perplexity': 1230.772101800968}\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(\n",
    "    n_vocab=vocab_size,\n",
    "    num_layers=num_layers,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size= hidden_size\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "dataloader = train_dl\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, min_lr=1e-6, patience=10) \n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, (state_h, state_c) = model(x)\n",
    "        loss = criterion(y_pred.transpose(1, 2), y)\n",
    "        perplexity = math.exp(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch % 10 == 0):\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item(), 'perplexity': perplexity })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save And Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../resources/nn_lstm_model_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(\n",
    "    n_vocab=vocab_size,\n",
    "    num_layers=2,\n",
    "    embedding_dim = 100,\n",
    "    hidden_size= 128\n",
    ")\n",
    "model.load_state_dict(torch.load('../resources/nn_lstm_model_state'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([139768, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_embeddings = model.state_dict()['emb.weight']\n",
    "trained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139768/139768 [51:07<00:00, 45.56it/s] \n"
     ]
    }
   ],
   "source": [
    "with open('../resources/trained_word2vec_embeddings', 'wb') as fout:\n",
    "    fout.write(gensim.utils.to_utf8(\"%s %s\\n\" % (trained_embeddings.size(0), trained_embeddings.size(1))))\n",
    "    for word, _ in tqdm(word_counts.most_common()):\n",
    "        index = word_to_index[word]\n",
    "        embedding = trained_embeddings[index]\n",
    "        fout.write(gensim.utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val.item()) for val in embedding))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ბიჭი რის გამოც მიღებული მთავარია მაშინ'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word2index(w):\n",
    "    try:\n",
    "        return word_to_index[w]\n",
    "    except:\n",
    "        return word_to_index['<pad>']\n",
    "\n",
    "\n",
    "def predict(model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[word2index(w) for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x)\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        while(index_to_word[word_index] == '<pad>'):\n",
    "            word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(index_to_word[word_index])\n",
    "    return ' '.join(words)\n",
    "\n",
    "predict(model, 'ბიჭი', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'გოგო შევიდა კაფეში დავიწყებ ვერ უყვიროდნენ საკუთარ სიტყვას ღმერთებმა სულიერ'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'გოგო შევიდა კაფეში', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'მერე რა რომ ზამთარია რომელშიც ითქვა შუახნის მწუხრი ველთა სანუგეშოდ და'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'მერე რა რომ ზამთარია', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ხვალ სადაც ვუჩივლებდი ასევე ნახსენები უნდა ფორმალობად ბოლომდე'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'ხვალ', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(context, model, index_list, num_beams=3):\n",
    "    if num_beams < 0: \n",
    "        return 1, -1\n",
    "    y_pred, (state_h, state_c) = model(context)\n",
    "    last_word_logits = y_pred[0][-1]\n",
    "    predictions = torch.nn.functional.softmax(last_word_logits, dim=0).detach()\n",
    "    top_words = torch.topk(predictions, dim=-1, k=10)\n",
    "    indices = top_words.indices\n",
    "    values = top_words.values\n",
    "    top_results = []\n",
    "    for indice, pr in zip(indices, values):\n",
    "        l = context.tolist()[0].copy()\n",
    "        l.append(indice.item())\n",
    "        l = l[-10:]\n",
    "        new_context = torch.tensor(l).unsqueeze(dim=0)\n",
    "        prob, word_index = beam_search(new_context, model, index_list, num_beams=num_beams-1)\n",
    "        prob = prob * pr.item()\n",
    "        top_results.append((prob, indice.item()))\n",
    "    top_results = sorted(top_results, key=lambda tup: tup[0])\n",
    "    \n",
    "    for prob, word_index in top_results:\n",
    "        if word_index not in index_list:\n",
    "            return prob, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'გუშინ საქართველოს პრეზიდენტის და სხვა დროს ამ უფლება იმისა'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_with_beamsearch(model, context, next_words):\n",
    "    model.eval()\n",
    "\n",
    "    words = context.split(' ')\n",
    "    index_list = [word_to_index['<pad>']]\n",
    "    \n",
    "    for i in range(0, next_words):\n",
    "        ind = ([word2index(w) for w in words[i:]][0])\n",
    "        index_list.append(ind)\n",
    "        x = torch.tensor([[word2index(w) for w in words[i:]]])\n",
    "        _, prediction_indice = beam_search(x, model, index_list)\n",
    "        words.append(index_to_word[prediction_indice])\n",
    "    return ' '.join(words)\n",
    "\n",
    "generate_with_beamsearch(model, 'გუშინ', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'დღეს როდესაც ყველა მნიშვნელოვანი მთავარი ინფორმაციისთვის რომ მისი მხრიდან'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_beamsearch(model, 'დღეს', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'არასოდეს ვიცი კი ვერ ახსენებ სიმპათიას თუ'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_beamsearch(model, 'არასოდეს', 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
